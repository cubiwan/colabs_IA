{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyP45KHerAH8leN4psBeH9HG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cubiwan/colabs_IA/blob/main/bark_with_voice_clone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d7Yiu__XjFV"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/serp-ai/bark-with-voice-clone.git\n",
        "%cd bark-with-voice-clone\n",
        "\n",
        "!pip install git+https://github.com/suno-ai/bark.git\n",
        "\n",
        "!git clone https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer/\n",
        "%cd bark-voice-cloning-HuBERT-quantizer\n",
        "!pip install -r requirements.txt\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bark.generation import load_codec_model, generate_text_semantic\n",
        "from encodec.utils import convert_audio\n",
        "\n",
        "import torchaudio\n",
        "import torch\n",
        "\n",
        "device = 'cuda' # or 'cpu'\n",
        "model = load_codec_model(use_gpu=True if device == 'cuda' else False)"
      ],
      "metadata": {
        "id": "YF-t8vJtYelH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n",
        "from hubert.hubert_manager import HuBERTManager\n",
        "hubert_manager = HuBERTManager()\n",
        "hubert_manager.make_sure_hubert_installed()\n",
        "hubert_manager.make_sure_tokenizer_installed()"
      ],
      "metadata": {
        "id": "_agIMRJSY74K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n",
        "# Load HuBERT for semantic tokens\n",
        "from hubert.pre_kmeans_hubert import CustomHubert\n",
        "from hubert.customtokenizer import CustomTokenizer\n",
        "\n",
        "# Load the HuBERT model\n",
        "hubert_model = CustomHubert(checkpoint_path='data/models/hubert/hubert.pt').to(device)\n",
        "\n",
        "# Load the CustomTokenizer model\n",
        "tokenizer = CustomTokenizer.load_from_checkpoint('data/models/hubert/tokenizer.pth').to(device)  # Automatically uses the right layers"
      ],
      "metadata": {
        "id": "3-os80nHY9Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subir el fichero con la muestra de audio audio.wav al directorio bark-with-voice-clone"
      ],
      "metadata": {
        "id": "i7yvGWphZFOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and pre-process the audio waveform\n",
        "audio_filepath = 'audio.wav' # the audio you want to clone (under 13 seconds)\n",
        "wav, sr = torchaudio.load(audio_filepath)\n",
        "wav = convert_audio(wav, sr, model.sample_rate, model.channels)\n",
        "wav = wav.to(device)"
      ],
      "metadata": {
        "id": "7XKTZ_7oZCsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_vectors = hubert_model.forward(wav, input_sample_hz=model.sample_rate)\n",
        "semantic_tokens = tokenizer.get_token(semantic_vectors)\n",
        "\n",
        "# Extract discrete codes from EnCodec\n",
        "with torch.no_grad():\n",
        "    encoded_frames = model.encode(wav.unsqueeze(0))\n",
        "codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1).squeeze()  # [n_q, T]\n",
        "\n",
        "# move codes to cpu\n",
        "codes = codes.cpu().numpy()\n",
        "# move semantic tokens to cpu\n",
        "semantic_tokens = semantic_tokens.cpu().numpy()\n",
        "\n",
        "import numpy as np\n",
        "voice_name = 'output' # whatever you want the name of the voice to be\n",
        "output_path = 'bark/assets/prompts/' + voice_name + '.npz'\n",
        "np.savez(output_path, fine_prompt=codes, coarse_prompt=codes[:2, :], semantic_prompt=semantic_tokens)"
      ],
      "metadata": {
        "id": "BuMiJvlCaETT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bark.api import generate_audio\n",
        "from transformers import BertTokenizer\n",
        "from bark.generation import SAMPLE_RATE, preload_models, codec_decode, generate_coarse, generate_fine, generate_text_semantic\n",
        "\n",
        "# Enter your prompt and speaker here\n",
        "text_prompt = \"Hello world\"\n",
        "voice_name = \"output\" # use your custom voice name here if you have one\n",
        "\n",
        "# download and load all models\n",
        "preload_models(\n",
        "    text_use_gpu=True,\n",
        "    text_use_small=False,\n",
        "    coarse_use_gpu=True,\n",
        "    coarse_use_small=False,\n",
        "    fine_use_gpu=True,\n",
        "    fine_use_small=False,\n",
        "    codec_use_gpu=True,\n",
        "    force_reload=False,\n",
        "    path=\"models\"\n",
        ")\n",
        "\n",
        "# simple generation\n",
        "audio_array = generate_audio(text_prompt, history_prompt=voice_name, text_temp=0.7, waveform_temp=0.7)\n",
        "\n",
        "# generation with more control\n",
        "x_semantic = generate_text_semantic(\n",
        "    text_prompt,\n",
        "    history_prompt=voice_name,\n",
        "    temp=0.7,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        ")\n",
        "\n",
        "x_coarse_gen = generate_coarse(\n",
        "    x_semantic,\n",
        "    history_prompt=voice_name,\n",
        "    temp=0.7,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        ")\n",
        "x_fine_gen = generate_fine(\n",
        "    x_coarse_gen,\n",
        "    history_prompt=voice_name,\n",
        "    temp=0.5,\n",
        ")\n",
        "audio_array = codec_decode(x_fine_gen)\n",
        "\n"
      ],
      "metadata": {
        "id": "sp4iXxR1aHHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generar un reproductor en el Colab\n",
        "from IPython.display import Audio\n",
        "# play audio\n",
        "Audio(audio_array, rate=SAMPLE_RATE)"
      ],
      "metadata": {
        "id": "_xz5UumyagSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Crear un fichero output.wav\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "# save audio\n",
        "filepath = \"output.wav\" # change this to your desired output path\n",
        "write_wav(filepath, SAMPLE_RATE, audio_array)"
      ],
      "metadata": {
        "id": "vUFFeyLBafJf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}