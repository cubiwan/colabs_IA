{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuFwQnOkACIexoB66ixXeu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cubiwan/colabs_IA/blob/main/Embbedings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo del uso de embbedings para calcular la similitud de textos.\n",
        "\n",
        "Para ello usaremos la librería sentence-transformers (https://github.com/UKPLab/sentence-transformers) Podemos ver la documentación en: https://www.sbert.net/index.html"
      ],
      "metadata": {
        "id": "NPQZJ-iURbGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalamos la librería\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "c6BWNdgFIQOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "#Cargamos el modelo\n",
        "#Hay mas modelos disponibles en https://www.sbert.net/docs/pretrained_models.html\n",
        "sbert_model = SentenceTransformer('all-mpnet-base-v2')"
      ],
      "metadata": {
        "id": "EqAWKp7nHbZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para calcular lo parecidas que son dos sentencia usaremos la similitud coseno (*cos_sim*) => u ⋅ v /∣u∣∣v∣ Siendo u y v vectores. 1 significa que son idénticos, 0 que no tienen relación y -1 que son contrarios."
      ],
      "metadata": {
        "id": "Z1eVUPszs_Vh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Estas son las sentencias con las que vamos a comparar nuestro texto de búsqueda. Las sentencias han sido obtenidas de la Wikipedia en inglés, en concreto la primera del articulo de mecánica cuántica y las siguientes de la definición de física clásica."
      ],
      "metadata": {
        "id": "MUzARgzcehiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"a fundamental theory in physics that provides a description of the physical properties of nature at the scale of atoms and subatomic particles.\",\n",
        "    \"refers to theories of physics that do not use the quantisation paradigm, which includes classical mechanics and relativity.\",\n",
        "    \"physical objects ranging from those larger than atoms and molecules, to objects in the macroscopic and astronomical realm\",\n",
        "    \"in the context of general and special relativity, classical theories are those that obey Galilean relativity.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "IWMG__qMKpXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buscamos *Quantum mechanics*, deberia de dar como mayor similitud el primer texto. Fijaros en la trampa de que el segundo incluye *quantisation paradigm* para \"engañar\" al modelo y ver si es capaz de buscar por \"significado\" y no solo por \"similitud de las palabras\""
      ],
      "metadata": {
        "id": "vrXC8PiBen-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Quantum mechanics\"\n",
        "query_embedding = sbert_model.encode([query])\n",
        "\n",
        "for sentece in sentences:\n",
        "  sim = util.cos_sim(query_embedding, sbert_model.encode([sentece]))\n",
        "  print(\"similarity = \", sim)"
      ],
      "metadata": {
        "id": "s5_umRZtIk_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso deberia de dar el primer texto como el menos similar. Sin embargo falla, y considera el menos similar el tercer texto, sin embargo si que acierta con el segundo y cuarto texto."
      ],
      "metadata": {
        "id": "SckDsoOKtUKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Classical physics\"\n",
        "query_embedding = sbert_model.encode([query])\n",
        "\n",
        "for sentece in sentences:\n",
        "  sim = util.cos_sim(query_embedding, sbert_model.encode([sentece]))\n",
        "  print(\"similarity = \", sim)"
      ],
      "metadata": {
        "id": "LXFRqd9zMzVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso es una prueba para ver como funciona con diferentes lenguajes, el modelo que usamos por defecto no es multidioma asi que deberia de fallar.\n",
        "\n"
      ],
      "metadata": {
        "id": "WC63PpjLbn3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Mecánica cuántica\"\n",
        "query_embedding = sbert_model.encode([query])\n",
        "\n",
        "for sentece in sentences:\n",
        "  sim = util.cos_sim(query_embedding, sbert_model.encode([sentece]))\n",
        "  print(\"similarity = \", sim)"
      ],
      "metadata": {
        "id": "Z1MFWrIMLGhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último un truco. Si normalizamos los vectores, esto significa que le damos longitud uno sin modificar la dirección del mismo, podemos usar el producto escalar (*dot_score*), mucho más rápido que la similitud coseno.\n",
        "\n",
        "Si partimos de la similitud coseno **u ⋅ v /∣u∣∣v∣** Al tener distancia 1 los módulos || son 1 por lo que el divisor desaparece y queda solo el producto escalar **u ⋅ v**"
      ],
      "metadata": {
        "id": "EIMVzYwhcBuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings = sbert_model.encode(sentences)\n",
        "\n",
        "query = \"Quantum mechanics\"\n",
        "query_embedding = sbert_model.encode([query], normalize_embeddings = True)\n",
        "\n",
        "for sentece in sentences:\n",
        "  sim = util.dot_score(query_embedding, sbert_model.encode([sentece], normalize_embeddings = True))\n",
        "  print(\"similarity = \", sim)\n"
      ],
      "metadata": {
        "id": "9dQPJeRmSI2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tamaño del vector:"
      ],
      "metadata": {
        "id": "r3R4lwupe7QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding = sbert_model.encode([query])\n",
        "\n",
        "print(\"Tamaño del emdedding: \", len(query_embedding))"
      ],
      "metadata": {
        "id": "v8DGhz9kDyjC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}