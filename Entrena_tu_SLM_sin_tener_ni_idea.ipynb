{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwWnRVUap8T/JCkZzmFcXQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cubiwan/colabs_IA/blob/main/Entrena_tu_SLM_sin_tener_ni_idea.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cómo entrenar tu propio modelo pequeño de lenguaje sin tener ni idea de lo que estas haciendo"
      ],
      "metadata": {
        "id": "bzQqbo7QOaiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1**\n",
        "Instalamos [llama.cpp](https://github.com/ggerganov/llama.cpp) y lo compilamos (si lo tienes instalado en local puedes pasar a los siguientes pasos)"
      ],
      "metadata": {
        "id": "GNB1Le50F7cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ggerganov/llama.cpp\n",
        "%cd llama.cpp\n",
        "!make"
      ],
      "metadata": {
        "id": "ZxhfiyYrGuvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.a**\n",
        "Si quieres entrenar un modelo inspirado en Shakespeare sigue este camino"
      ],
      "metadata": {
        "id": "YVvvUdoFO6u-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Descargamos el dataset\n",
        "!wget https://raw.githubusercontent.com/brunoklein99/deep-learning-notes/master/shakespeare.txt\n",
        "\n",
        "#Entrenamos el modelo\n",
        "!./train-text-from-scratch --vocab-model ./models/ggml-vocab-llama.gguf --ctx 64 --embd 256 --head 8 --layer 16 --checkpoint-in chk-shakespeare-256x16.gguf --checkpoint-out chk-shakespeare-256x16.gguf --model-out ggml-shakespeare-256x16-f32.gguf --train-data \"shakespeare.txt\" -b 16 --seed 1 --adam-iter 256 --no-checkpointing"
      ],
      "metadata": {
        "id": "i5ZdwKddGdjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.b**\n",
        "Si quieres entrenar un modelo inspirado en El Quijote sigue este camino"
      ],
      "metadata": {
        "id": "V1rds8LDPNVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#descargamos el dataset\n",
        "!wget https://gist.githubusercontent.com/jsdario/6d6c69398cb0c73111e49f1218960f79/raw/8d4fc4548d437e2a7203a5aeeace5477f598827d/el_quijote.txt"
      ],
      "metadata": {
        "id": "dDo0QWg7HG4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpiamos el texto"
      ],
      "metadata": {
        "id": "4zPaicdN0wK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre del archivo de entrada y salida\n",
        "nombre_archivo_entrada = \"el_quijote.txt\"\n",
        "nombre_archivo_salida = \"el_quijote_clean.txt\"\n",
        "\n",
        "# Función para reemplazar caracteres especiales\n",
        "def reemplazar_caracteres_especiales(texto):\n",
        "    # Mapeo de caracteres especiales a sus equivalentes sin tilde/diéresis\n",
        "    reemplazos = {\n",
        "        \"á\": \"a\",\n",
        "        \"é\": \"e\",\n",
        "        \"í\": \"i\",\n",
        "        \"ó\": \"o\",\n",
        "        \"ú\": \"u\",\n",
        "        \"ü\": \"u\",\n",
        "        \"Á\": \"A\",\n",
        "        \"É\": \"E\",\n",
        "        \"Í\": \"I\",\n",
        "        \"Ó\": \"O\",\n",
        "        \"Ú\": \"U\",\n",
        "        \"Ü\": \"U\",\n",
        "        \"ñ\": \"n\",\n",
        "        \"Ñ\": \"N\"\n",
        "    }\n",
        "\n",
        "    # Realizar los reemplazos\n",
        "    for clave, valor in reemplazos.items():\n",
        "        texto = texto.replace(clave, valor)\n",
        "\n",
        "    return texto\n",
        "\n",
        "try:\n",
        "    # Abrir el archivo de entrada para lectura\n",
        "    with open(nombre_archivo_entrada, \"r\", encoding=\"utf-8\") as archivo_entrada:\n",
        "        # Leer el contenido del archivo\n",
        "        contenido = archivo_entrada.read()\n",
        "\n",
        "    # Reemplazar caracteres especiales\n",
        "    contenido_modificado = reemplazar_caracteres_especiales(contenido)\n",
        "\n",
        "    # Abrir el archivo de salida para escritura\n",
        "    with open(nombre_archivo_salida, \"w\", encoding=\"utf-8\") as archivo_salida:\n",
        "        # Escribir el contenido modificado en el archivo de salida\n",
        "        archivo_salida.write(contenido_modificado)\n",
        "\n",
        "    print(\"Reemplazo completado con éxito. El archivo de salida se ha creado como\", nombre_archivo_salida)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"No se pudo encontrar el archivo de entrada: {nombre_archivo_entrada}\")\n",
        "except Exception as e:\n",
        "    print(\"Se produjo un error:\", str(e))"
      ],
      "metadata": {
        "id": "Y0VFG0BCqEas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#entrenamos el modelo con el dataset limpio\n",
        "!./train-text-from-scratch --vocab-model ./models/ggml-vocab-llama.gguf --ctx 64 --embd 256 --head 8 --layer 16 --checkpoint-in chk-quijote-256x16.gguf --checkpoint-out chk-quijote-256x16.gguf --model-out ggml-quijote-256x16-f32.gguf --train-data \"el_quijote_clean.txt\" -b 16 --seed 1 --adam-iter 256 --no-checkpointing"
      ],
      "metadata": {
        "id": "2ONXWwx90ko_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.c**\n",
        "Si quieres entrenar un modelo con datos estructurados sigue este camino"
      ],
      "metadata": {
        "id": "R0UWHgoF1x97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero generamos los datos"
      ],
      "metadata": {
        "id": "tpAd3T4rOmXM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTCDyvknprhm"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Define las estructuras de datos\n",
        "agente = [\"oye\", \"hey\", \"ia\", \"bot\", \"eh\", \"escucha\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n",
        "\n",
        "accion = [\n",
        "    [\"prende\", \"enciende\", \"pon\", \"activa\", \"ilumina\", \"conecta\", \"enchufa\", \"on\"],\n",
        "    [\"apaga\", \"quita\", \"desconecta\", \"desenchufa\", \"off\"]\n",
        "]\n",
        "\n",
        "det1 = [\"el\", \"la\", \"\"]\n",
        "\n",
        "luz = [\"luz\", \"bombilla\", \"iluminacion\", \"led\"]\n",
        "aire = [\"aire\", \"ac\", \"acondicionador\", \"aire acondicionado\", \"frio\"]\n",
        "\n",
        "det2 = [\"del\", \"de la\", \"de\", \"la\", \"el\", \"\"]\n",
        "\n",
        "lugar = [\n",
        "    [\"bano\", \"lavabo\", \"cuarto de bano\", \"sanitario\", \"wc\"],\n",
        "    [\"dormitorio\", \"cama\"],\n",
        "    [\"entrada\", \"recibidor\", \"pasillo\", \"recibidor\"],\n",
        "    [\"cocina\", \"fogon\", \"fogones\"],\n",
        "    [\"salon\", \"comedor\"],\n",
        "    [\"despacho\", \"oficina\"],\n",
        "    [\"casa\", \"hogar\", \"\"]\n",
        "]\n",
        "\n",
        "det3 = [\"la\",\"lo\", \"le\", \"\", \"\"]\n",
        "\n",
        "comando_accion = [\"ON\", \"OFF\"]\n",
        "comando_lugar = [\"LUZ_BN\", \"LUZ_DR\", \"LUZ_EN\", \"LUZ_CO\", \"LUZ_SL\", \"LUZ_DP\", \"AC\"]\n",
        "\n",
        "\n",
        "def crea_sentencia():\n",
        "  # Elegir una acción (0 o 1) y un lugar (0...6) al azar\n",
        "  indice_accion = random.randint(0, 1)\n",
        "  indice_lugar = random.randint(0, 6)\n",
        "\n",
        "  # Elegir una acción y un lugar basados en los índices\n",
        "  accion_elegida = random.choice(accion[indice_accion])\n",
        "  lugar_elegido = random.choice(lugar[indice_lugar])\n",
        "\n",
        "  # Si el indice_lugar lugar es 6 (casa), elegir una palabra del array \"aire\"\n",
        "  if indice_lugar == 6:\n",
        "      aparato_elegido = random.choice(aire)\n",
        "  else:\n",
        "      aparato_elegido = random.choice(luz)\n",
        "\n",
        "  # Construir la oración\n",
        "  if random.randint(0, 1) == 1:\n",
        "    orden = f\"{random.choice(agente)} {accion_elegida} {random.choice(det1)} {aparato_elegido} {random.choice(det2)} {lugar_elegido}\"\n",
        "  else:\n",
        "    orden = f\"{random.choice(agente)} {random.choice(det1)} {aparato_elegido} {random.choice(det2)} {lugar_elegido} {accion_elegida}{random.choice(det3)}\"\n",
        "\n",
        "  # Construir la sentencia\n",
        "  sentencia = f\"<s>\\n [ORDEN] {orden}\\n [COMANDO] {comando_lugar[indice_lugar]} {comando_accion[indice_accion]}\\n </s>\"\n",
        "\n",
        "  return sentencia\n",
        "\n",
        "\n",
        "# Nombre del archivo de texto en el que se guardarán las sentencias\n",
        "nombre_archivo = \"sentencias.txt\"\n",
        "\n",
        "contador_sentencias = 0\n",
        "\n",
        "# Abre el archivo en modo escritura\n",
        "with open(nombre_archivo, \"w\") as archivo:\n",
        "    # Itera para crear y guardar las sentencias\n",
        "    for _ in range(1000000):\n",
        "        sentencia = crea_sentencia()\n",
        "        archivo.write(sentencia + \"\\n\")\n",
        "        contador_sentencias += 1\n",
        "        if contador_sentencias % 10000 == 0:\n",
        "            print(f\"Se han generado {contador_sentencias} sentencias.\")\n",
        "\n",
        "print(f\"Se han creado y guardado {contador_sentencias} sentencias en el archivo:\", nombre_archivo)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos el modelo"
      ],
      "metadata": {
        "id": "Q1mLyh222MK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./train-text-from-scratch --vocab-model ./models/ggml-vocab-llama.gguf --ctx 64 --embd 256 --head 16 --layer 32 --checkpoint-in chk-onoff-256x16x32.gguf --checkpoint-out chk-onoff-256x16x32.gguf --model-out ggml-onoff-256x16x32-f32.gguf --train-data \"sentencias.txt\" -b 64 --seed 1 --adam-iter 512 --no-checkpointing"
      ],
      "metadata": {
        "id": "RPdlQJ2NHGZ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}